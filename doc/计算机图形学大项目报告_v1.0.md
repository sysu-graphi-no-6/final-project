# 计算机图形学大项目

| 版本 | 日期      |
| ---- | --------- |
| V1.0 | 2019-6-15 |

## 项目介绍以及实现结果

项目实现的内容是一个“寻找花儿”的游戏。玩家在一个自然场景中（有草丛、路、树或者小溪）。会随机出现一些花儿，玩家触碰花儿花儿消失，增加一分，而如果触碰到蜘蛛，扣除一分。玩家需要注意不能掉入小溪或者掉出边界。当然，为了玩家更高兴完成任务，可以按下`O`键使用**飞天模式**完成任务，此时玩家不受重力束缚，按下`Space`键上升而按下`Q`键下降。在普通模式下按下`Space`键进行跳跃，跳跃时也可前后左右移动。按下`WSAD`键分别控制玩家前后左右移动。玩家移动距离取决于摄像机的前向量以及右向量。

项目效果如视频所示。视频在当前目录中。

## 开发环境

开发平台：`Visual Studio2017`

库：`stb_image` `assimp` `freetype`(未加入)

## 实现部分

### 摄像机系统

#### 透视投影

![ perspective_frustum](https://learnopengl-cn.github.io/img/01/08/perspective_frustum.png)

由于透视原理，两条线在很远的地方看起来是相交的。这是透视需要模仿的效果，同时这也是通过透视矩阵完成的。该矩阵可以修改每一个顶点的w值，距离观察者越远w分量便越大。而该矩阵还会将所有的顶点坐标映射到(-w, w)的范围上。
$$
out=\begin{bmatrix}
   x/w\\
   y/w \\
   z/w
  \end{bmatrix}
$$
与正交矩阵类似，我们可以调用GLM中的内置函数：

```
projection = glm::perspective(glm::radians(camera->Zoom), (float)windowsWidth / (float)windowsHeight, 0.1f, 100.0f);
```

其中，第一个参数fov定义了视野（Field of View），并且设置了观察空间的大小。第二个为宽高比，可以通过窗口的宽除以高得到。第三个和第四个参数定义了平截头体的近和远平面。近平面一般设为`1.0f`而远平面设为`100.0f`。如果顶点在近平面与远平面内，且处于平截头体内，则会被渲染。

#### LookAt矩阵

利用三个相互正交的向量，可以构件一个新的坐标空间，利用这三个轴另外加上一个平移向量可以创建一个矩阵。利用这个矩阵乘以任意向量可以变换到该坐标空间内
$$
LookAt=out=\begin{bmatrix}
   R_x & R_y & R_z & 0\\
   U_x & U_y & U_z & 0\\
   D_x & D_y & D_z & 0\\
  0 & 0 & 0 & 0
  \end{bmatrix} * 
  \begin{bmatrix}
   1 & 0 & 0 & -P_x\\
   0 & 1 & 0 & -P_y\\
   0 & 0 & 1 & -P_z\\
  0 & 0 & 0 & 1
  \end{bmatrix}
$$
#### 初始化属性值

```c++
// 属性值
    // 相机的位置
    glm::vec3 Position = glm::vec3(0.0f, 2.0f, 0.0f);
    // 相机的前向量
    glm::vec3 Front = glm::vec3(1.0f, 0.0f, 0.0f);
    // 相机的上向量
    glm::vec3 Up = glm::vec3(0.0f, 1.0f, 0.0f);
    // 相机的右向量
    glm::vec3 Right;
    // 观察坐标
    glm::vec3 WorldUp = glm::vec3(0.0f, 0.0f, 0.0f);
```

#### LookAt矩阵的使用

```c++
shaderManager->blockShader.use();
		glm::mat4 projection(1.0f);
		glm::mat4 view(1.0f);
		glm::mat4 model(1.0f);
		view = glm::lookAt(camera->Position, camera->Position + camera->Front, camera->Up);
		projection = glm::perspective(glm::radians(camera->Zoom), (float)windowsWidth / (float)windowsHeight, 0.1f, 100.0f);
		shaderManager->directionalLight.setMat4("projection", projection);
		shaderManager->directionalLight.setMat4("view", view);
```



#### 视觉移动

我们利用欧拉角（Euler Angle），通过在3D空间中旋转的三个值（pitch, yaw, roll）进行视角的移动。利用它们的结合，我们可以算出3D空间中的任何旋转的向量。

![img](https://learnopengl-cn.github.io/img/01/09/camera_pitch_yaw_roll.png)

这三个值的定义如下：

- 俯仰角，描述如何往上或往下看的角
- 偏航角，左右看的程度
- 滚转角，摄像机翻滚的程度

对于给定的俯仰角与偏航角，可以把其转换为代表新方向向量的3D向量。如下图：

![img](https://learnopengl-cn.github.io/img/01/09/camera_triangle.png)

其中的`hypotenuse = 1`。我们可以知道邻边的长度分别为 `cos x`与`sin y`。它们取决于所给的角度theta。同样地，我们通过下面的图片：

![img](https://learnopengl-cn.github.io/img/01/09/camera_pitch.png)

如果我们在xz平面上，向y轴看去，我们可以计算其长度y方向的强度（Strength）。对于给定的俯仰角theta，我们可以使用语句表示：

```
direction.y = sin(glm::radians(pitch));
```

同样地，我们需要更新x与z分量：

```
direction.x = cos(glm::radians(pitch));
direction.z = cos(glm::radians(pitch));
```

除此之外，我们还需要找到合适的分量计算偏航角。

![img](https://learnopengl-cn.github.io/img/01/09/camera_yaw.png)

如上图，x分量取决于`cos(yaw)`的值，z分量取决于`sin(yaw)`。摄像机位置移动后物体的投射投影方法上面的代码已经给出,这里不多说了。

#### 实现按键的移动

我们通过跟踪一个时间差（Deltatime），把所有速度乘以这个`deltaTime`值，可以调整移动速度。如果`deltaTime`值很大，那么上一帧渲染花费更多的时间，所以这一帧需要更高的速度进行平衡。

```c++
void escapePress(GLFWwindow *window, float& deltaTime) {
	if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS)
		glfwSetWindowShouldClose(window, true);

	// 单独进行处理提高运算速度
	else if (glfwGetKey(window, GLFW_KEY_W) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_A) == GLFW_PRESS) {
		// WA
		// cout << "WA" << endl;
		camera->ProcessKeyboard(FORWARD_LEFT, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_W) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_A) == GLFW_RELEASE && glfwGetKey(window, GLFW_KEY_D) == GLFW_RELEASE) {
		// W
		// cout << "W" << endl;
		camera->ProcessKeyboard(FORWARD, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_W) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_D) == GLFW_PRESS) {
		// WD
		// cout << "WD" << endl;
		camera->ProcessKeyboard(FORWARD_RIGHT, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_S) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_A) == GLFW_PRESS) {
		// SA
		// cout << "SA" << endl;
		camera->ProcessKeyboard(BACKWARD_LEFT, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_S) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_A) == GLFW_RELEASE && glfwGetKey(window, GLFW_KEY_D) == GLFW_RELEASE) {
		// S
		// cout << "S" << endl;
		camera->ProcessKeyboard(BACKWARD, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_S) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_D) == GLFW_PRESS) {
		// SD
		// cout << "SD" << endl;
		camera->ProcessKeyboard(BACKWARD_RIGHT, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_A) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_W) == GLFW_RELEASE && glfwGetKey(window, GLFW_KEY_S) == GLFW_RELEASE) {
		// A
		// cout << "A" << endl;
		camera->ProcessKeyboard(LEFT, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_D) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_W) == GLFW_RELEASE && glfwGetKey(window, GLFW_KEY_S) == GLFW_RELEASE) {
		// D
		// cout << "D" << endl;
		camera->ProcessKeyboard(RIGHT, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_O) == GLFW_PRESS) {
		isPress = true;
	}
	else if (isPress && glfwGetKey(window, GLFW_KEY_O) == GLFW_RELEASE) {
		isPress = false;
		camera->ProcessKeyboard(FLYSKY, deltaTime);
	}
	// 跳跃单独处理
	if (glfwGetKey(window, GLFW_KEY_SPACE) == GLFW_PRESS)
		camera->ProcessKeyboard(JUMP, deltaTime);
	else if (glfwGetKey(window, GLFW_KEY_Q) == GLFW_PRESS) {
		camera->ProcessKeyboard(DOWN, deltaTime);
	}
}
```

其中`WSAD`四个按键控制摄像机前后左右移动，而对于同时按下两个键的情况，也同时考虑以提高位置更新的效率。如果用户按下`O`则打开**飞天模式**。在飞天模式中摄像机可以摆脱重力的束缚。如果在飞天模式下，按下`Q`键可以下降，而在普通模式下，按下空格键可以实现跳跃。

##### 按键移动的距离

根据此时按下的按键（可以是一个或者两个同时），可以对齐行走方向进行判断，如下：

```c++
if (direction == FORWARD)
        forwardVector += speed;
    if (direction == BACKWARD)
        forwardVector -= speed;
    if (direction == LEFT)
        rightVector -= speed;
    if (direction == RIGHT)
        rightVector += speed;
    if (direction == FORWARD_LEFT) {
        forwardVector += speed;
        rightVector -= speed;
    }
    if (direction == FORWARD_RIGHT) {
        forwardVector += speed;
        rightVector += speed;
    }
    if (direction == BACKWARD_LEFT) {
        forwardVector -= speed;
        rightVector -= speed;
    }
    if (direction == BACKWARD_RIGHT) {
        forwardVector -= speed;
        rightVector += speed;
    }
```

其中，`speed`为某一方向移动的距离，这里设为`2.0f`。而在这之后，根据当前摄像机的`前向量`以及`右向量`计算摄像机位置的位移量。当然，需要判断移动后位置的合法性（需要进行碰撞检测，而如果下方为空则自由落体）。如果用户处于飞天模式`flysky`为`true`，则直接进行碰撞检测即可。

```c++
 if (forwardVector != 0.0f || rightVector != 0.0f) {
        //行走不改变y轴坐标
        glm::mat4 vm = getViewMatrix();
        glm::vec3 forward = glm::vec3(vm[0][2], 0.0f, vm[2][2]);
        glm::vec3 strafe = glm::vec3(vm[0][0], 0.0f, vm[2][0]);

        afterMove = Position + (-forwardVector * forward + rightVector * strafe) * cameraSpeed;
        // 保留小数，减少计算量 0.001
        int remain = 3;
        if (abs(afterMove.x - Position.x) < 0.05f) {
            afterMove.x = Position.x;
        }
        if (abs(afterMove.z - Position.z) < 0.05f) {
            afterMove.z = Position.z;
        }
       // afterMove = glm::vec3(getFloat(afterMove.x, remain), getFloat(afterMove.y, remain), getFloat(afterMove.z, remain));
       //cout << "Pos:"<<Position.x << " " << Position.y << " " << Position.z << endl;
      //cout << "move:" << afterMove.x << " " << afterMove.y << " " << afterMove.z << endl;
       //afterMove = glm::vec3((int)afterMove.x, (int)afterMove.y, (int)afterMove.z);
        if (PhysicsEngine::getInstance()->HorizontalCollisionDetect(Position, afterMove)) {
            if (!engine->isFreeAll && !engine->isJumping && !flysky) {
                if (engine->WalkingVerticalCollisionDetect(afterMove)) {
                    //// 增加位移量
                    //float offset = 0.5f;
                    //int axBiggerthanPx = 0;
                    //int azBiggerthanPz = 0;
                    //if (afterMove.x < Position.x) {
                    //    axBiggerthanPx = -1;
                    //}
                    //else if (afterMove.x > Position.x) {
                    //    axBiggerthanPx = 1;
                    //}
                    //if (afterMove.z < Position.z) {
                    //    azBiggerthanPz = -1;
                    //}
                    //else if (afterMove.z > Position.z) {
                    //    azBiggerthanPz = 1;
                    //}
                    //float x_offset = axBiggerthanPx > 0 ? 1.0f : (axBiggerthanPx == 0 ? 0.0f : -1.0f);
                    //float z_offset = azBiggerthanPz > 0 ? 1.0f : (azBiggerthanPz == 0 ? 0.0f : -1.0f);

                    // Position = glm::vec3(afterMove.x + x_offset, Position.y, afterMove.z + z_offset);
                    Position = glm::vec3(afterMove.x, Position.y, afterMove.z);
                    FreeAll();
                    return;
                }
            }
            Position = afterMove;
        }
    }
```

![1560619442502](asserts\1560619442502.png)

### 光照

#### 点光源

phong光照模型由环境（Ambient）、漫反射（Diffuse）以及镜面（Sepcular）光照组成。

- 环境光照会改变光照的强度，实现物体的明暗效果
- 漫反射以及镜面光照则改变物体受光照的影响
  - 漫反射分量越大，物体对着光源的那部分就会越亮
  - 镜面光照分量越大则物体反光能力越强（越容易在物体表面上出现亮点）

段着色器（包括阴影）如下：

```c++
#version 450 core

out vec4 FragColor;

in VS_OUT {
    vec3 FragPos;
    vec3 Normal;
    vec2 TexCoords;
    vec4 FragPosLightSpace;
} fs_in;

uniform sampler2D diffuseTexture;
uniform sampler2D shadowMap;

uniform vec3 lightColor;
uniform vec3 lightPos;
uniform vec3 viewPos;
// uniform vec3 objectColor;

uniform float ambientStrength;
uniform float specularStrength;
uniform float shininess;
uniform float diffuseFactor;


float ShadowCalculation(vec4 fragPosLightSpace, vec3 normal, vec3 lightDir)
{
    // 执行透视算法，将将w转化为(-1, 1)
    vec3 projCoords = fragPosLightSpace.xyz / fragPosLightSpace.w;
    // 从(-1,1)变换到(0,1)
    projCoords = projCoords * 0.5 + 0.5;
    // 得到光的位置视野下最近的深度
    float closestDepth = texture(shadowMap, projCoords.xy).r; 
    // 简单获取投影向量的z坐标，等于来自光的透视视角的片元的深度
    float currentDepth = projCoords.z;

    // 避免阴影失真
    // 使用点乘
    float bias = max(0.5 * (1.0 - dot(normal, lightDir)), 0.005);

    // 从纹理像素四周对深度贴图采样，并取其平均值
    float shadow = 0.0;
    vec2 texelSize = 1.0 / textureSize(shadowMap, 0);
    for(int x = -1; x <= 1; ++x)
    {
        for(int y = -1; y <= 1; ++y)
        {
            float pcfDepth = texture(shadowMap, projCoords.xy + vec2(x, y) * texelSize).r; 
            shadow += currentDepth - bias > pcfDepth  ? 1.0 : 0.0;
        }    
    }
    shadow /= 9.0;
    
    // 只投影向量的z坐标大于1.0则shadow的值强制设为0.0
    if(projCoords.z > 1.0){
        shadow = 0.0;
    }
    return shadow;
}

void main()
{
    // 进行材质处理，如果透明度小于0.1的片段丢弃
    vec4 texColor = texture(diffuseTexture, fs_in.TexCoords);
    if(texColor.a < 0.1)
        discard;
    vec3 objectColor = texture(diffuseTexture, fs_in.TexCoords).rgb;           
    vec3 normal = normalize(fs_in.Normal);
    //计算距离衰减
   
    // ambient环境光
    vec3 ambient =  ambientStrength * lightColor;
    // diffuse 漫反射
    vec3 lightDir = normalize(lightPos - fs_in.FragPos);
    float diff = max(dot(lightDir, normal), 0.0);
    vec3 diffuse = diff * lightColor * diffuseFactor;
    // specular 镜面
    vec3 viewDir = normalize(viewPos - fs_in.FragPos);
    vec3 reflectDir = reflect(-lightDir, normal);
    float spec = 0.0;
    vec3 halfwayDir = normalize(lightDir + viewDir);  
    spec = pow(max(dot(normal, halfwayDir), 0.0), 64);
    vec3 specular = spec * lightColor * specularStrength;  

    // 计算阴影
    float shadow = ShadowCalculation(fs_in.FragPosLightSpace, normal, lightDir);                      
    vec3 lighting = (ambient + (1.0 - shadow) * (diffuse + specular)) * objectColor;
    FragColor = vec4(lighting, 1.0);
}
```

#### 环境光照

环境光照中，对于输入的环境因子`ambientStrength`，乘以输入的光照的颜色，可以得到环境光照`ambient`。该`ambient`变量乘以光照颜色可以得到片段的颜色（在计算结果中得到的仅仅是片段颜色的一部分）。

```c++
// ambient
vec3 ambient = ambientStrength * lightColor;
```

#### 漫反射

##### 坐标转换

首先，我们需要在顶点着色器中将输入的顶点位置坐标乘以模型矩阵，将其转变为世界看空间坐标。顶点着色器定义如下：

```c++
#version 450 core
layout (location = 0) in vec3 aPos;
layout (location = 1) in vec3 aNormal;
layout (location = 2) in vec2 aTexCoords;
layout (location = 3) in vec3 aOffset;

out vec2 TexCoords;

out VS_OUT {
    vec3 FragPos;
    vec3 Normal;
    vec2 TexCoords;
    vec4 FragPosLightSpace;
} vs_out;

uniform mat4 projection;
uniform mat4 view;
uniform mat4 model;
uniform mat4 lightSpaceMatrix;

void main()
{
    gl_Position = projection * view * model * vec4(aPos + aOffset, 1.0f);
    vs_out.FragPos = vec3(model * vec4(aPos, 1.0f));
    vs_out.Normal = transpose(inverse(mat3(model))) * aNormal;
    vs_out.TexCoords = aTexCoords;
    vs_out.FragPosLightSpace = lightSpaceMatrix * vec4(vs_out.FragPos, 1.0f);
    
}
```

因为法向量是一个方向向量而不能表达空间中的特定位置（坐标），所以我们通过法线矩阵进行法向量向世界坐标的变换。在运用中，我们使用`inverse`以及`transpose`函数生成发现矩阵。

```c++
Normal = mat3(transpose(inverse(model))) * aNormal;  
```

##### 利用法向量进行计算

漫反射能够对物体产生显著的视觉影响。对于在程序中手动输入并且传到段着色器中的法向量`Normal Factor`（法向量为垂直于顶点表面的单位向量），我们还需要有如下的操作：

- 计算光源位置与片段位置之间的方向向量，即光的方向向量。
- 将光的方向向量进行标准化，因为我们只关注方向。
- 将标准化后的法向量`norm`与光的方向向量`lightDir`进行点乘，计算出光源对当前片段的漫反射影响。
  - 如果两个向量的角度越大，点乘的结果越小，则漫反射分量越小。
- 进行合法性判断，如果点乘结果小于零则置为0（角度大于90度时为负数）。
- 计算结果乘以物体颜色以及漫反射参数`diffuseFactor`，得到结果。

```c++
    // diffuse 
    vec3 norm = normalize(Normal);
    vec3 lightDir = normalize(lightPos - FragPos);
    float diff = max(dot(norm, lightDir), 0.0);
    vec3 diffuse = diff * lightColor * diffuseFactor;
```

#### 镜面光照

镜面光照与光的方向向量以及物体的法向量决定，它与观察向量也是有关的。我们通过法向量计算其反射向量，再计算反射向量与视线方向的角度差。夹角越小则镜面光的影响越大（产生高光）。

在段着色器中，我们需要更改其镜面因素`specularStrength`。同时，我们还需对`lightDir`进行取反，而`reflect`函数需要第一个向量是从光源指向片段位置的向量，第二个则是标准化后的法向量。计算的时候，需要注意视线方向与反射方向向量的点乘需要确保大于或等于0，之后取幂值（幂值为输入的`shininess`变量，称反光度。如果反光度越高，反射光能力越强，散射越小，同时高光的点越小。）

```c++
// specular
    vec3 viewDir = normalize(viewPos - FragPos);
    vec3 reflectDir = reflect(-lightDir, norm);  
    float spec = pow(max(dot(viewDir, reflectDir), 0.0), shininess);
    vec3 specular = specularStrength * spec * lightColor;  
```

最后，算出了全部分量。

```c++
vec3 lighting = (ambient + (1.0 - shadow) * (diffuse + specular)) * objectColor;
FragColor = vec4(lighting, 1.0);
```

#### 平行光

对于平行光，只需要给出指定的方向，即可完成平行光照射的效果。在片段着色器中，我们添加`uniform vec3 dir;`，即光照方向，并进行归一化，计算过程与点光源类似。最后，将两种光源的计算效果叠加，可以获得多光源光照效果。

```c++
vec3 CalcDirLight(vec3 objectColor)
{
    vec3 normal = normalize(fs_in.Normal);
    //计算距离衰减
   
    // ambient环境光
    vec3 ambient =  ambientStrength * lightColor;
    // diffuse 漫反射
    vec3 lightDir = normalize(-dir);
    float diff = max(dot(lightDir, normal), 0.0);
    vec3 diffuse = diff * lightColor * diffuseFactor;
    // specular 镜面
    vec3 viewDir = normalize(viewPos - fs_in.FragPos);
    vec3 reflectDir = reflect(-lightDir, normal);
    float spec = 0.0;
    vec3 halfwayDir = normalize(lightDir + viewDir);  
    spec = pow(max(dot(normal, halfwayDir), 0.0), 64);
    vec3 specular = spec * lightColor * specularStrength;  

    // 计算阴影
    float shadow = ShadowCalculation(fs_in.FragPosLightSpace, normal, lightDir);                      
    vec3 lighting = (ambient + (1.0 - shadow) * (diffuse + specular)) * objectColor;
    return lighting;
}
```

### 实例化数组

如果按照原来的方法进行渲染，会产生大量的实例达到性能瓶颈。通过实例化数组，先绑定其偏移量（作为顶点属性）和顶点缓冲对象，以后调用着色器的时候可以直接传入一个偏移量数组，而该顶点属性仅仅在顶点着色器渲染新的实例时才被更新。

在顶点着色器中，我们添加偏移量uniform数组作为实例化数组：

```c++
#version 450 core
layout (location = 0) in vec3 aPos;
layout (location = 1) in vec3 aNormal;
layout (location = 2) in vec2 aTexCoords;
layout (location = 3) in vec3 aOffset;

...

void main()
{
    gl_Position = projection * view * model * vec4(aPos + aOffset, 1.0f);
	...
    
}
```

而在一开始进行绑定的时候，我们需要进行如下操作：

```c++
		// 最大支持40 * 40
        glGenBuffers(1, &instanceVBO);
        glBindBuffer(GL_ARRAY_BUFFER, instanceVBO);
        glBufferData(GL_ARRAY_BUFFER, sizeof(glm::vec3) * MAX_BLOCK, NULL, GL_DYNAMIC_DRAW);
        glBindBuffer(GL_ARRAY_BUFFER, 0);
		...
		glBindBuffer(GL_ARRAY_BUFFER, instanceVBO);
        glEnableVertexAttribArray(3);
        glVertexAttribPointer(3, 3, GL_FLOAT, GL_FALSE, sizeof(glm::vec3), (void*)0);
        glVertexAttribDivisor(3, 1);
        ...
```

之后我们还需要设置它的顶点属性指针，并启用顶点属性：

```
glEnableVertexAttribArray(2);
glBindBuffer(GL_ARRAY_BUFFER, instanceVBO);
glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, 2 * sizeof(float), (void*)0);
glBindBuffer(GL_ARRAY_BUFFER, 0);   
glVertexAttribDivisor(2, 1);
```

其中的`glVertexAttribDivisor`告诉OpenGL更新顶点属性内容至新一组数据的时候。如上，设置为1，则告诉OpenGL每渲染一哥实例更新一次属性。

在使用的时候，只需要将偏移量的坐标传入即可。

```c++
ResourceManager* manager = ResourceManager::getInstance();
glBindBuffer(GL_ARRAY_BUFFER, manager->getInstanceVBO());
glBufferSubData(GL_ARRAY_BUFFER, 0, sizeof(glm::vec3) * count, &position[0]);
glBindBuffer(GL_ARRAY_BUFFER, 0);
```

### 纹理贴图

#### 传入单张图片

因为传入图片格式为`png`，其中有的通道数为4，即`RGBA`，有的则为3，即`RGB`。所以需要对其通道数进行判断。其中，调用的库为`stb_image`。之后需要进行参数的设置，在S、T方向进行镜像重复。在这之后，还需要对其进行纹理过滤，使用`GL_NEWAREST`即邻近过滤。

```c++
unsigned int ResourceManager::loadTexture(const GLchar* path)
{
    unsigned int textureID;
    glGenTextures(1, &textureID);

    glBindTexture(GL_TEXTURE_2D, textureID);

    int width, height, nrChannels;
    unsigned char *data = stbi_load(path, &width, &height, &nrChannels, 0);
    if (data)
    {
        GLenum format = nrChannels == 3 ? GL_RGB : GL_RGBA;
        glTexImage2D(GL_TEXTURE_2D, 0, format, width, height, 0, format, GL_UNSIGNED_BYTE, data);
        // glTexImage2D(GL_TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, data);
        stbi_image_free(data);
        //glGenerateMipmap(GL_TEXTURE_2D);
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_MIRRORED_REPEAT);
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_MIRRORED_REPEAT);
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
        glBindTexture(GL_TEXTURE_2D, 0);
    }
    else
    {
        std::cout << "Cubemap texture failed to load at path: " << path << std::endl;
        stbi_image_free(data);
    }
    return textureID;
}


```

#### 传入多张图片作为动画

过程与上面雷速，只是需要对图片进行截取。贴图大小为`32×32`。在截取后传入到数组中以供后续使用。这里返回的是一个`unsigned int*`指针，因为有多张贴图。

```c++
unsigned int* ResourceManager::loadTextures( const GLchar* path, int count) {
    unsigned int* textures = new unsigned int[count];
    int width, height, nrChannels;
    unsigned char* data = stbi_load(path, &width, &height, &nrChannels, 0);
    if (data)
    {
        // 进行图片的切分
        int singleHeight = height / count;

        for (int i = 0; i < count; i++) {
            // Create Texture
            glGenTextures(1, &textures[i]);
            glBindTexture(GL_TEXTURE_2D, textures[i]);
            GLenum format = nrChannels == 3 ? GL_RGB : GL_RGBA;
            glTexImage2D(GL_TEXTURE_2D, 0, format, width, singleHeight, 0, format, GL_UNSIGNED_BYTE, data + (nrChannels * width * singleHeight) * i);
            //glGenerateMipmap(GL_TEXTURE_2D);
            glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_MIRRORED_REPEAT);
            glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_MIRRORED_REPEAT);
            glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
            glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
            glBindTexture(GL_TEXTURE_2D, 0);
        }
        stbi_image_free(data);
        return textures;
    }
    else
    {
        std::cout << "Cubemap texture failed to load at path: " << path << std::endl;
        stbi_image_free(data);
        return NULL;
    }
    return NULL;
}
```

#### 面剔除

对于交叉对象的贴图（比如蘑菇、花等），因为它是不规则的，其渲染出的矩形之内、贴图之外会产生非常难看的黑色。这里通过面剔除进行修正。在片段着色器中，我们获取纹理贴图的RGBA值，如果其透明度小于0.1（即A通道值小于0.1）该面被剔除。

```c++
// 进行材质处理，如果透明度小于0.1的片段丢弃
    vec4 texColor = texture(diffuseTexture, fs_in.TexCoords);
    if(texColor.a < 0.1)
        discard;
```

#### 应用

##### 顶点数据

在进入while循环之前我们需要将顶点属性与顶点缓冲对象绑定。这里将方块六个面分别创建其VAO，即不同的顶点属性。对于VBO，共用即可。对于顶点属性，这里分为两类：方块的六个面分为一类；而交叉的对象（比如花草、蘑菇等）作为另一类。顶点属性的步长参数为`8 * sizeof(GLfloat)`。初始化过程如下：

```c++
// 进行方块的初始化
    void InitCube() {
       ...
        Single_InitCube(cubeVAO_top, cubeVBO_top, TOP);
        Single_InitCube(cubeVAO_bottom, cubeVBO_bottom, BOTTOM);
        Single_InitCube(cubeVAO_front, cubeVBO_front, FRONT);
        Single_InitCube(cubeVAO_back, cubeVBO_back, BACK);
        Single_InitCube(cubeVAO_left, cubeVBO_left, LEFT);
        Single_InitCube(cubeVAO_right, cubeVBO_right, RIGHT);
        Single_InitCube(crossVAO, crossVBO, CROSS);
    }

    // 进行单个方块的绑定
    void Single_InitCube(unsigned int& VAO, unsigned int &VBO, RenderDirection dir){
        // top
        glGenVertexArrays(1, &VAO);
        glGenBuffers(1, &VBO);
        // 根据方向渲染
        glBindBuffer(GL_ARRAY_BUFFER, VBO);
        if (dir == TOP) {
            glBufferData(GL_ARRAY_BUFFER, sizeof(top), top, GL_STATIC_DRAW);
        }
        else if (dir == BOTTOM) {
            glBufferData(GL_ARRAY_BUFFER, sizeof(bottom), bottom, GL_STATIC_DRAW);
        }
        else if (dir == FRONT) {
            glBufferData(GL_ARRAY_BUFFER, sizeof(front), front, GL_STATIC_DRAW);
        }
        else if (dir == BACK) {
            glBufferData(GL_ARRAY_BUFFER, sizeof(back), back, GL_STATIC_DRAW);
        }
        else if (dir == LEFT) {
            glBufferData(GL_ARRAY_BUFFER, sizeof(left), left, GL_STATIC_DRAW);
        }
        else if (dir == RIGHT) {
            glBufferData(GL_ARRAY_BUFFER, sizeof(right), right, GL_STATIC_DRAW);
        }
        else if (dir == CROSS) {
            glBufferData(GL_ARRAY_BUFFER, sizeof(cross), cross, GL_STATIC_DRAW);
        }
        // Link vertex attributes
        glBindVertexArray(VAO);
        glEnableVertexAttribArray(0);
        glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(GLfloat), (GLvoid*)0);
        glEnableVertexAttribArray(1);
        glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(GLfloat), (GLvoid*)(3 * sizeof(GLfloat)));
        glEnableVertexAttribArray(2);
        glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, 8 * sizeof(GLfloat), (GLvoid*)(6 * sizeof(GLfloat)));

      	...

        glBindVertexArray(0);
        glBindBuffer(GL_ARRAY_BUFFER, 0);
       // glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, 0);
    }
```

```c++
 // --------------渲染部分-----------------------
    GLfloat front[48] = {
      ...
    };
    GLfloat back[48] = {
       ...
    };
    GLfloat left[48] = {
      ...

    };
    GLfloat right[48] = {
       ...   

    };
    GLfloat bottom[48] = {
       ...

    };

    GLfloat top[48] = {
      ...
    };

    GLfloat cross[96] = {
      ...
    };

```

##### 着色器

方块的顶点着色器需要与纹理贴图适应：

```c++
#version 450 core
...
layout (location = 2) in vec2 aTexCoords;

out vec2 TexCoords;

out VS_OUT {
    vec3 FragPos;
    vec3 Normal;
    vec2 TexCoords;
    vec4 FragPosLightSpace;
} vs_out;
...

void main()
{
	...
    vs_out.Normal = transpose(inverse(mat3(model))) * aNormal;
    vs_out.TexCoords = aTexCoords;
    vs_out.FragPosLightSpace = lightSpaceMatrix * vec4(vs_out.FragPos, 1.0f);
    
}
```

对于顶点着色器传入的变量`TextCoords`，方块的段着色器需要取出其颜色的`RGB`值从而进行光照模型的计算。

```c++
in VS_OUT {
    vec3 FragPos;
    vec3 Normal;
    vec2 TexCoords;
    vec4 FragPosLightSpace;
} fs_in;
...
void main()
{
    // 进行材质处理，如果透明度小于0.1的片段丢弃
    vec4 texColor = texture(diffuseTexture, fs_in.TexCoords);
   ...
    
}

```

##### 渲染

在渲染部分，我们通过`glDrawArraysInstanced`进行实例绑定，我们需要绘制的是三角形，即`GL_TRIANGLES`，其顶点属性共有6个（交叉的对象有12个），对于`drawCount`变量是需要绘制对象的数量（可以一次绘制出多个相同对象），它将纹理赋值给片段着色器的采样器：

```c++
void ResourceManager::RenderFace(unsigned int texture, RenderDirection dir, unsigned int drawCount) {
    glActiveTexture(GL_TEXTURE0);
    glBindTexture(GL_TEXTURE_2D, texture);
    if (dir == TOP) {
        glBindVertexArray(cubeVAO_top);
    }
    else if (dir == BOTTOM) {
        glBindVertexArray(cubeVAO_bottom);
    }
    else if (dir == FRONT) {
        glBindVertexArray(cubeVAO_front);
    }
    else if (dir == BACK) {
        glBindVertexArray(cubeVAO_back);
    }
    else if (dir == LEFT) {
        glBindVertexArray(cubeVAO_left);
    }
    else if (dir == RIGHT) {
        glBindVertexArray(cubeVAO_right);
    }
    if (dir != CROSS) {
        // Render Cube
        glDrawArraysInstanced(GL_TRIANGLES, 0, 6, drawCount);
        glBindVertexArray(0);
    }
    else {
        glBindVertexArray(crossVAO);
        // Render Cube
        glDrawArraysInstanced(GL_TRIANGLES, 0, 12, drawCount);
        glBindVertexArray(0);
    }
}
```

### 阴影

#### 深度贴图

在这一步骤中，我们需要从光的透视图中渲染深度纹理。我们需要为渲染的深度贴图创建帧缓冲对象。之后创建2D纹理，提供给深度缓冲使用，其中纹理格式定义为`GL_DEPTH_COMPONENT`，高度和宽度均为1024。

```c++
/ 为渲染的深度贴图创建一个帧缓冲对象
    GLuint depthMapFBO;
    glGenFramebuffers(1, &depthMapFBO);
    // 创建深度纹理
    GLuint depthMap;
    glGenTextures(1, &depthMap);
    glBindTexture(GL_TEXTURE_2D, depthMap);

    glTexImage2D(GL_TEXTURE_2D, 0, GL_DEPTH_COMPONENT, SHADOW_WIDTH, SHADOW_HEIGHT, 0, GL_DEPTH_COMPONENT, GL_FLOAT, NULL);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);
```

下一步，我们将生成的纹理作为深度缓冲。在这个过程中，将`glDrawBuffer`与`glReadBuffer`设置为`GL_NONE`，因为我们仅需要其深度信息而不需要颜色信息。

```c++
glBindFramebuffer(GL_FRAMEBUFFER, depthMapFBO);
glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_TEXTURE_2D, depthMap, 0);
glDrawBuffer(GL_NONE);
glReadBuffer(GL_NONE);
glBindFramebuffer(GL_FRAMEBUFFER, 0);
```

#### 渲染

在while循环中，我们需要先渲染深度贴图，之后再渲染设定好的场景。这里选择的是透视投影。

```c++
// 透视投影
		lightProjection = glm::perspective(100.0f, (float)SHADOW_WIDTH / (float)SHADOW_HEIGHT, near_plane, far_plane);
```

#### 光源空间变换

我们需要从光源位置的视野来投影场景中的不同物体。即我们需要通过透视投影矩阵或者正交投影矩阵进行物体表面点位置的变换。投影矩阵间接决定可视区域，而如果图元不在贴图区域中则不产生阴影，所以我们需要保证投影视锥的大小。同时，为了使得物体表面点能够变换到光源位置视角的可见空间中，我们使用`glm::lookAt`函数。

```c++
        lightView = glm::lookAt(lightPos, glm::vec3(0.0f), glm::vec3(0.0, 1.0, 0.0));
        lightSpaceMatrix = lightProjection * lightView;

        simpleDepthShader.use();
        simpleDepthShader.setMat4("lightSpaceMatrix", lightSpaceMatrix);
```

其中`lightSpaceMatrix`为投影与`lookAt`矩阵结合的变换矩阵，只要给`shader`提供光空间的投影与视图矩阵，我们就可以渲染深度贴图了。

```c++
 // 渲染深度贴图
        glViewport(0, 0, SHADOW_WIDTH, SHADOW_HEIGHT);
        glBindFramebuffer(GL_FRAMEBUFFER, depthMapFBO);
        glClear(GL_DEPTH_BUFFER_BIT);
        RenderScene(simpleDepthShader);
        glBindFramebuffer(GL_FRAMEBUFFER, 0);

        glCullFace(GL_BACK);
```



#### 渲染至深度贴图

通过`shadow_mapping_depth`着色器，将顶点变换到光源位置对应的空间。顶点着色器如下：

```
#version 450 core
layout (location = 0) in vec3 aPos;

uniform mat4 lightSpaceMatrix;
uniform mat4 model;

void main()
{
    gl_Position = lightSpaceMatrix * model * vec4(aPos, 1.0);
}
```

该顶点着色器将模型中的顶点通过矩阵`lightSpaceMatrix`变换到光空间中。

同时我们需要定义一个空的段着色器：

```
#version 450 core

void main()
{             
    // gl_FragDepth = gl_FragCoord.z;
}
```

运行完该段着色器后（我们仅需要其深度值而不需要其颜色值），深度缓冲被更新。



#### 阴影渲染

在顶点着色器`shadow.vs`中，我们依旧利用立方体的位置、法向量以及纹理坐标。将顶点变换到光空间。`FragPosLightSpace`向量是输出到段着色器中的，它是变换矩阵`lightSpaceMatrix`将世界坐标系中的顶点位置映射到光空间对应坐标系中的结果。其中的`diffuseTexture`为0，即阴影外为0.0。而`shadowMap`为1，即fragment在阴影中为1.0。`diffuse`和`specular`颜色会乘以该阴影元素。由于散射，阴影并非全黑，所以将ambient分量从乘法中剔除。阴影渲染函数不再赘述。

```c++
float ShadowCalculation(vec4 fragPosLightSpace, vec3 normal, vec3 lightDir)
{
    // 执行透视算法，将将w转化为(-1, 1)
    vec3 projCoords = fragPosLightSpace.xyz / fragPosLightSpace.w;
    // 从(-1,1)变换到(0,1)
    projCoords = projCoords * 0.5 + 0.5;
    // 得到光的位置视野下最近的深度
    float closestDepth = texture(shadowMap, projCoords.xy).r; 
    // 简单获取投影向量的z坐标，等于来自光的透视视角的片元的深度
    float currentDepth = projCoords.z;

    // 避免阴影失真
    // 使用点乘
    float bias = max(0.5 * (1.0 - dot(normal, lightDir)), 0.005);

    // 从纹理像素四周对深度贴图采样，并取其平均值
    float shadow = 0.0;
    vec2 texelSize = 1.0 / textureSize(shadowMap, 0);
    for(int x = -1; x <= 1; ++x)
    {
        for(int y = -1; y <= 1; ++y)
        {
            float pcfDepth = texture(shadowMap, projCoords.xy + vec2(x, y) * texelSize).r; 
            shadow += currentDepth - bias > pcfDepth  ? 1.0 : 0.0;
        }    
    }
    shadow /= 9.0;
    
    // 只投影向量的z坐标大于1.0则shadow的值强制设为0.0
    if(projCoords.z > 1.0){
        shadow = 0.0;
    }
    return shadow;
}
```

#### 阴影改进

参考之前的阴影绘制作业，这里加上了阴影失真避免、悬浮避免、采样过多避免以及PCF。其过程不多赘述。

### 模型导入 
这里使用的是最为流行的Assimp作为我们的模型导入库，项目中所使用的模型都是从免费模型网下载的
#### 基础环境配置
Assimp能够导入很多种不同的模型文件格式（并也能够导出部分的格式），它会将所有的模型数据加载至Assimp的通用数据结构中。当Assimp加载完模型之后，我们就能够从Assimp的数据结构中提取我们所需的所有数据了。配置Assimp 我们需要先下载源码，用cmake进行编译 再用对应的vs跑一遍，获取dll和lib，再将之放入我们的环境目录中 即可使用。这里如果没有安装Directx9，可能会出现一些小问题，再就是需要选择对应项目配置的dll，我个人使用的是x86的。
#### 模型导入方法
按照opengl教程，主要是实现mesh和model类，其中mesh是网格，本身包含了渲染所需要的所有相关数据，像是顶点位置、法向量、纹理坐标、面(Face)和物体的材质。
```c++
vector<Vertex> vertices;
vector<unsigned int> indices;
vector<Texture> textures;
unsigned int VAO;
void Draw(Shader* shader) {
		shader->setVec3("light.ambient", glm::vec3(0));
		shader->setVec3("light.diffuse", glm::vec3(0));
		shader->setVec3("light.specular", glm::vec3(0));
		shader->setFloat("light.shininess", 32);
		shader->setInt("material.specular", 0);
		shader->setInt("material.diffuse", 0);
		shader->setInt("material.normal", 0);
		shader->setInt("material.height", 0);
		bool hasColor = false;
		bool hasTexture = false;
		for (unsigned int i = 0; i < textures.size(); i++) {
			string name = textures[i].type;
			if (name == "color") {
				hasColor = true;
				shader->setVec3("light.ambient", textures[i].ambientColor);
				shader->setVec3("light.diffuse", textures[i].diffuseColor);
				shader->setVec3("light.specular", textures[i].specularColor);
				if (textures[i].shininess != 0) {
					shader->setFloat("light.shininess", textures[i].shininess);
				}
			}
			else {
				hasTexture = true;
				glActiveTexture(GL_TEXTURE0 + i);
				shader->setInt(name.c_str(), i);
				glBindTexture(GL_TEXTURE_2D, textures[i].id);
			}
		}
		shader->setInt("hasColor", hasColor);
		shader->setInt("hasTexture", hasTexture);

		glBindVertexArray(VAO);
		glDrawElements(GL_TRIANGLES, indices.size(), GL_UNSIGNED_INT, 0);
		glBindVertexArray(0);

		glActiveTexture(GL_TEXTURE0);
	}
```
上述代码存储了模型的基本信息。Draw用于绘制mesh。
```c++
class Model 
{
    public:
        /*  函数   */
        Model(char *path)
        {
            loadModel(path);
        }
        void Draw(Shader shader);   
    private:
        /*  模型数据  */
        vector<Mesh> meshes;
        string directory;
        /*  函数   */
        void loadModel(string path);
        void processNode(aiNode *node, const aiScene *scene);
        Mesh processMesh(aiMesh *mesh, const aiScene *scene);
        vector<Texture> loadMaterialTextures(aiMaterial *mat, aiTextureType type, 
                                             string typeName);
};
```
Model类包含了一个Mesh对象的vector，Draw函数就是遍历了所有网格，并调用mesh各自的Draw函数。processMesh函数用于访问网格的相关属性，并将它们储存到我们对象中。

### 天空盒

天空和包括其周围的6个贴图，使得其中的玩家以为出于比实际大的环境中。

#### 天空盒的加载

这里直接使用教程给出的`loadCubemap`函数，输入为两个文件的路径：

```c++
unsigned int loadCubemap(vector<std::string> faces)
{
    unsigned int textureID;
    glGenTextures(1, &textureID);
    glBindTexture(GL_TEXTURE_CUBE_MAP, textureID);

    int width, height, nrChannels;
    for (unsigned int i = 0; i < faces.size(); i++)
    {
        unsigned char *data = stbi_load(faces[i].c_str(), &width, &height, &nrChannels, 0);
        if (data)
        {
            glTexImage2D(GL_TEXTURE_CUBE_MAP_POSITIVE_X + i, 
                         0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, data
            );
            stbi_image_free(data);
        }
        else
        {
            std::cout << "Cubemap texture failed to load at path: " << faces[i] << std::endl;
            stbi_image_free(data);
        }
    }
    glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
    glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
    glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
    glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
    glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_R, GL_CLAMP_TO_EDGE);

    return textureID;
}
```

```
vector<string> skybox_faces
    {
        "resource/skybox/nevada_lf.jpg",
        "resource/skybox/nevada_rt.jpg",
        "resource/skybox/nevada_up.jpg",
        "resource/skybox/nevada_dn.jpg",
        "resource/skybox/nevada_ft.jpg",
        "resource/skybox/nevada_bk.jpg"
    };
```

#### 天空盒的显示

天空盒的显示需要另外的VAO、VBO和顶点。所以我们需要重新定义顶点着色器以及片段着色器：

```c++
#version 450 core
layout (location = 0) in vec3 aPos;

out vec3 TexCoords;

uniform mat4 projection;
uniform mat4 view;

void main()
{
    TexCoords = aPos;
    gl_Position = projection * view * vec4(aPos, 1.0);
}
```

其中输入的坐标作为纹理坐标，将被片段着色器使用。

```c++
#version 450 core
out vec4 FragColor;

in vec3 TexCoords;

uniform samplerCube skybox;

void main()
{    
    FragColor = texture(skybox, TexCoords);
}
```

片段着色器非常直观。我们将顶点属性的位置向量作为纹理的方向向量，并使用它从立方体贴图中采样纹理值。

#### 渲染

在渲染的时候，我们应该禁用深度写入，而且天空和也是被第一个渲染的物体（它在最底部）。

```c++ 
 // 天空盒
    skyboxShader.setText("skybox.vs", "skybox.frag");
    cubemapTexture = loadCubemap(skybox_faces);
    // skybox VAO
    glGenVertexArrays(1, &skyboxVAO);
    glGenBuffers(1, &skyboxVBO);
    glBindVertexArray(skyboxVAO);
    glBindBuffer(GL_ARRAY_BUFFER, skyboxVBO);
    glBufferData(GL_ARRAY_BUFFER, sizeof(skyboxVertices), &skyboxVertices, GL_STATIC_DRAW);
    glEnableVertexAttribArray(0);
    glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);
    // 设置天空盒
    skyboxShader.use();
    skyboxShader.setInt("skybox", 0);
```

```c++
 // 画出天空盒
    glDepthFunc(GL_LEQUAL);  // change depth function so depth test passes when values are equal to depth buffer's content
    skyboxShader.use();
    glm::mat4 view = glm::mat4(glm::mat3(Camera::getInstance()->getViewMatrix())); // remove translation from the view matrix
    skyboxShader.setMat4("view", view);
    skyboxShader.setMat4("projection", projection);
    // skybox cube
    glBindVertexArray(skyboxVAO);
    glActiveTexture(GL_TEXTURE0);
    glBindTexture(GL_TEXTURE_CUBE_MAP, cubemapTexture);
    glDrawArrays(GL_TRIANGLES, 0, 36);
    glBindVertexArray(0);
    glDepthFunc(GL_LESS); // set depth function back to default
```

天空盒的位置不能随着玩家的位置变化而变化，所以我们需要移除观察矩阵中的位移部分，避免观察位置的影响。这里通过将4x4矩阵截取其左上角的3x3部分矩阵再变回4×4矩阵达到清除位移的效果。

```
glm::mat4 view = glm::mat4(glm::mat3(Camera::getInstance()->getViewMatrix()));
```

![1560619497030](asserts\1560619497030.png)

### 重力系统

#### 弹跳

这里迭代了两个版本。在第一个版本中，弹跳函数包括弹跳的所有过程，并且在上升以及下降过程都进行碰撞的检测。但是这样的计算使得弹跳在下降部分与自由落体检测功能重合（自由落体检测即检测摄像机下方是否存在方块，如果没有则自由落体），从而产生奇奇怪怪的bug，比如下降到一定程度突然又从速度0开始自由落体。所以在第二个版本的弹跳实现中，弹跳函数只负责上升阶段（即从初速度v0至0m/s）。

##### 初始化

首先需要赋予玩家一定的初速度`initialSpped`以及重力因素`gravityFactor`。为了减慢弹跳的过程使其更有真实感，我没谈添加了`slowingdownFactor`进行减速。在一开始的时候，我们需要判断玩家是否不处于飞天模式下并且不在弹跳或者自由落体过程中，并赋值参数：

```c++
void InitJumping() {
        isJumping = true;
        currentSpeed = initialSpeed;
        currentHeight = 0;
    }
```

#### 差分实现上升阶段

因为每一帧之间的间隔时间很短，我们可以利用每一帧之间的速度进行比较以及这段时间内移动距离的计算。首先，在每一帧都需要对玩家的状态进行判断。如果玩家除以弹跳并不处于自由落体过程中（即下降阶段），利用帧间的时间差，以及之前的速度算出当前速度，取平均速度乘以时间获得路程。这里取向下为正方向。当然其下一位置需要进行碰撞检测以避免穿模。之后对其速度进行更新。

```c++
if (engine->isJumping && !engine->isFreeAll) {
        // 弹跳函数只负责上升阶段
        // 利用重力加速度参数 (v + v0)/ 2 * t
        if (engine->currentSpeed > 0) {
            float nowSpeed = engine->currentSpeed + engine->gravityFactor * deltaTime * engine->slowingdownFactor;
            // 当前走过的路程
            engine->currentHeight = (nowSpeed + engine->currentSpeed) / 2.0f * deltaTime;
            // if (engine->currentHeight < 0.0f && engine->currentHeight > -0.1f) engine->currentHeight = 0.0f;
            
            engine->currentSpeed = nowSpeed;
            glm::vec3 afterMove = glm::vec3(Position.x, Position.y + engine->currentHeight, Position.z);
            //cout << "Height: " << (afterMove.y) << "  Speed: " << (engine->currentSpeed) << endl;
            if (engine->UpVerticalCollisionDetect(afterMove)) {
                Position = afterMove;
            }
            else {
                FreeAll();
            }
        }
        else {
            FreeAll();
        }
    }
```

#### 自由落体

自由落体的初始化与弹跳的初始化类似，需要设置初始高度、初始速度为0并且赋值`isFreeAll`为true代表自由落体开始。

```c++
void Camera::FreeAll() {
    PhysicsEngine* engine = PhysicsEngine::getInstance();
    engine->currentHeight = 0.0f;
    engine->currentSpeed = 0.0f;
    engine->isFreeAll = true;

}
```

同样在每一帧都需要对玩家的状态进行判断。如果此时是自由落体状态，与之前大弹跳过程类似，需要利用帧间的时间差济学宁速度的计算以及经过路程的计算。这里取向下为正方向。当然，离不开垂直方向的碰撞检测，如果下方出现方块，停止自由落体，而如果玩家此时依旧出于弹跳状态，取消其弹跳状态。

#### 自由落体的检测

```c++
else if (engine->isFreeAll) {
        float nowSpeed = engine->currentSpeed + engine->gravityFactor * deltaTime * engine->slowingdownFactor;
        // 当前走过的路程
        engine->currentHeight = (nowSpeed + engine->currentSpeed) / 2.0f * deltaTime;
        // if (engine->currentHeight < 0.0f && engine->currentHeight > -0.1f) engine->currentHeight = 0.0f;

        engine->currentSpeed = nowSpeed;
        glm::vec3 afterMove = glm::vec3(Position.x, Position.y + engine->currentHeight, Position.z);
        if (engine->DownVerticalCollisionDetect(afterMove)) {
            Position = afterMove;
        }
        else {
            engine->isFreeAll = false;
            if (engine->isJumping) {
                engine->isJumping = false;
            }
            engine->currentHeight = 0.0f;
            engine->currentSpeed = 0.0f;
            Position = glm::vec3(Position.x, round(Position.y), Position.z);
        }
    }
```

![1560619590990](asserts\1560619590990.png)

(按下O取消自由落体掉在地上)

#### 飞天模式

如果玩家出于飞天模式，按下Space键盘则增加其高度，按下Q键则降低其高度。当然也需要垂直方向的碰撞检测。

```c++
if (flysky && direction == JUMP) {
        afterMove = glm::vec3(Position.x, Position.y + 0.05f, Position.z);
        if (engine->UpVerticalCollisionDetect(afterMove)) {
            Position = afterMove;
        }
    }
    else if (flysky && direction == DOWN) {
        afterMove = glm::vec3(Position.x, Position.y - 0.05f, Position.z);
        if (engine->DownVerticalCollisionDetect(afterMove)) {
            Position = afterMove;
        }
    }
```

![1560619560475](asserts\1560619560475.png)

### 碰撞检测

项目中的碰撞检测方法有两种，一种是垂直以及水平方向分开的碰撞检测（我写的），另一种是AABB盒检测（另一位大佬写的）。前者用于摄像机移动位置合法性的判断，后者用于摄像机与目标物碰撞的判断。

#### 直接检测

在直接检测方法中，只需要存储方块对应位置的布尔值`true`表示该位置有方块即可。其实碰撞检测也是经过两个版本。第一个版本中使用`vector`容器存储位置的x和z坐标，而使用`map`存储其y轴坐标，因为这样直接利用摄像机y轴坐标作为key即可获得相应的键值对，特别方便。之后再对对应高度的所有方块进行遍历，如果所有位置的bool值都为`false`则没有发生碰撞。这样的效率是比较慢的，所以第二个版本改用三层`map`容器，利用`map`红黑树对于键值查找友好的特点直接进行位置合法性的判断。水平和垂直碰撞检测分开的好处在于可以减少碰撞检测计算的点以及计算量。而垂直方向的判断，只需要算出当前位置上方下方有无方块即可。不仅如此，在行走的时候也需要对每一步进行垂直和水平方向的碰撞检测 .，以避免水平方向出现方块或者垂直方向缺少方块。

##### 水平碰撞检测

水平碰撞检测中，只需找出水平方向的16个点（共两层高度，每层8个点）进行合法性判断即可。为了简化计算量，需要传入下一位置坐标，记录下一坐标相对于当前坐标x和z轴的偏差量获得方向并寻找对应位置进行合法性判断。

```c++
bool PhysicsEngine::HorizontalCollisionDetect(glm::vec3 currentPos, glm::vec3 nextPos) {

	int axBiggerthanPx = 0;
	int azBiggerthanPz = 0;
	if (nextPos.x < currentPos.x) {
		axBiggerthanPx = -1;
	}
	else if (nextPos.x > currentPos.x) {
		axBiggerthanPx = 1;
	}
	if (nextPos.z < currentPos.z) {
		azBiggerthanPz = -1;
	}
	else if (nextPos.z > currentPos.z) {
		azBiggerthanPz = 1;
	}
	int y_round = round(currentPos.y);
	int y_min = y_round - 1;

	// 进行每层8邻域水平检测，共两层
	/*
		* * *
		*   *
		* * *
	*/
	if (axBiggerthanPx == -1 && azBiggerthanPz == -1) {
		if (m[y_round][round(currentPos.x) - 1][round(currentPos.z) - 1] == true) {
			return false;
		}
		if (m[y_min][round(currentPos.x) - 1][round(currentPos.z) - 1] == true) {
			return false;
		}
	}
	else if (axBiggerthanPx == -1 && azBiggerthanPz == 0) {
		if (m[y_round][round(currentPos.x) - 1][round(currentPos.z)] == true) {
			return false;
		}
		if (m[y_min][round(currentPos.x) - 1][round(currentPos.z)] == true) {
			return false;
		}
	}
	else if (axBiggerthanPx == -1 && azBiggerthanPz == 1) {
		if (m[y_round][round(currentPos.x) - 1][round(currentPos.z) + 1] == true) {
			return false;
		}
		if (m[y_min][round(currentPos.x) - 1][round(currentPos.z) + 1] == true) {
			return false;
		}
	}
	else if (axBiggerthanPx == 0 && azBiggerthanPz == -1) {
		if (m[y_round][round(currentPos.x)][round(currentPos.z) - 1] == true) {
			return false;
		}
		if (m[y_min][round(currentPos.x)][round(currentPos.z) - 1] == true) {
			return false;
		}
	}
	else if (axBiggerthanPx == 0 && azBiggerthanPz == 1) {
		if (m[y_round][round(currentPos.x)][round(currentPos.z) + 1] == true) {
			return false;
		}
		if (m[y_min][round(currentPos.x)][round(currentPos.z) + 1] == true) {
			return false;
		}
	}
	else if (axBiggerthanPx == 1 && azBiggerthanPz == -1) {
		if (m[y_round][round(currentPos.x) + 1][round(currentPos.z) - 1] == true) {
			return false;
		}
		if (m[y_min][round(currentPos.x) + 1][round(currentPos.z) - 1] == true) {
			return false;
		}
	}
	else if (axBiggerthanPx == 1 && azBiggerthanPz == 0) {
		if (m[y_round][round(currentPos.x) + 1][round(currentPos.z)] == true) {
			return false;
		}
		if (m[y_min][round(currentPos.x) + 1][round(currentPos.z)] == true) {
			return false;
		}
	}
	else if (axBiggerthanPx == 1 && azBiggerthanPz == 1) {
		if (m[y_round][round(currentPos.x) + 1][round(currentPos.z) + 1] == true) {
			return false;
		}
		if (m[y_min][round(currentPos.x) + 1][round(currentPos.z) + 1] == true) {
			return false;
		}
	}
	return true;
}
bool PhysicsEngine::UpVerticalCollisionDetect(glm::vec3 pos) {
    if (m[round(pos.y + 0.5f)][round(pos.x)][round(pos.z)] == true) {
        return false;
    }
    return true;
}
```

##### 垂直碰撞检测

垂直碰撞检测分为上升阶段的碰撞检测以及下降阶段的碰撞检测。这样碰撞检测可以只关注y轴方向的即可。

```c++
// 弹跳时的检测
bool PhysicsEngine::DownVerticalCollisionDetect(glm::vec3 pos) {
    if (m[round(pos.y - 1.5f)][round(pos.x)][round(pos.z)] == true) {
        return false;
    }
    return true;
}

// 走时的检测
bool PhysicsEngine::WalkingVerticalCollisionDetect(glm::vec3 pos) {
    if (m[round(pos.y - 2.0f)][round(pos.x)][round(pos.z)] == true) {
        return false;
    }
    return true;
}
```

#### AABB盒检测
只是简单的判断人物对应位置与物体的位置判断 三轴坐标小于一定距离视为接触到 返回bool值

```c++
bool PhysicsEngine::CheckCollision(glm::vec3 pos, glm::vec3 next_pos) // AABB - AABB collision
{
	// x轴方向碰撞？
	bool collisionX = (abs(pos.x-next_pos.x) <=0.6 );
	// y轴方向碰撞？
	bool collisionY = (abs(pos.y - next_pos.y) <= 2);
	bool collisionZ = (abs(pos.z - next_pos.z) <= 0.6);
	// 只有两个轴向都有碰撞时才碰撞
	return collisionX && collisionY&&collisionZ;
}
```

### Gamma矫正

Gamma校正在最终的颜色输出上使用监视器Gamma的倒数，即在颜色显示到监视器时将每个颜色输出都加上翻转的Gamma曲线，最终颜色会变成线性的，这样中间色调会变得更亮。

这里设定的`gamma`参数为1.2，计算过程如下：

```c++
	// gamma
    float gamma = 1.2;
    lighting = pow(lighting, vec3(1.0/gamma));
    FragColor = vec4(lighting, 1.0);
```

![1560619636652](asserts\1560619636652.png)

(未添加Gamma矫正的老版本场景)

![1560619768562](asserts\1560619768562.png)

（添加了Gamma矫正，方块之间色差更小）

### 高级光照2

// 待完成

### 文字渲染

// 待完成

### 粒子系统

// 待完成

## 遇到的问题和解决方案

- 占用显存极大
  - 因为之前按照`learn-openGL`中的教程，VAO、VBO的绑定在while循环里面，所以占用了很大一部分的显存，只需要将其添加在while循环之前即可。
- 方块较多时显示效果较差，画面卡顿
  - 这里就需要引入`实例化数组`概念，每渲染一个实例才调用一次着色器，而不是每次渲染一个方块就调用一次，简化了渲染的过程，提高渲染效率。
- 摄像机移动的方法
  - 之前按照按下WSAD按键位置的前后左右变化的方法，与摄像头的视角角度毫无联系，显得特别突兀。所以移动采用与摄像机系统前向量与右向量关联的方法，让行走更加自如
- 面剔除
  - 比如蘑菇、花朵这样的对象渲染的时候在贴图外面有纯黑色存在，通过其贴图的A通道，即透明通道值进行判断，剔除小于0.1的部分即可。
- 基于多张图片的纹理加载
  - 如果直接返回函数内创建的作为局部变量的数组，因为函数已经返回所以被销毁为空。需要在函数内`new`一个数组，创建后传回指针，在析构函数中销毁。
- 实例化数组后只渲染一个方块
  - 在采用实例化数组，一次渲染多个方块的时候应该调用`glDrawArraysInstanced`函数且传入渲染数量，否则只会渲染一个。
- 重力系统
  - 重力系统经过两次迭代。跳跃函数应该只负责上升阶段而下降阶段应该交给自由落体函数。这样在下降阶段如果回到原来高度时下方没有方块才可以正常自由落体。
- 碰撞检测计算复杂，画面卡顿
  - 利用基于红黑树的`map`对有方块的位置进行存储。这样通过键值对即可进行位置合法性的判断。并且通过水平与垂直碰撞的分开计算，减少其计算量。
- 天空盒`Vertex`的正确对齐
  - 天空盒共六面24个顶点需要正确对齐，这需要花费很长的时间才能正确对齐，非常无奈。
- 模型导入时的环境配置
  -首先各类教程都讲得比较含糊 ，中间某些步骤会出现意想不到的bug，只能通过stackoverflow来寻求好的解决方案。
- 场景构建时存在的纹理错乱
  -由于一开始是直接声明场景中物体的具体个数，在改变场景外观后，可能会出现多重绘制而导致的贴图错乱。
- // 待完成

## 小组分工

- 谢桂鑫：模型导入、目标物体的随机生成与碰撞检测（AABB盒）、光照与阴影渲染的优化
- 陈伟昭：阴影与另外的高级光照 场景构建。
- 陈思航：方块渲染、摄像机系统、光照与阴影渲染、重力系统、视角移动与碰撞检测、模型导入、天空盒、静态纹理贴图（方块、交叉贴图）、动态纹理贴图、Gamma矫正。
- 王培钰：文字渲染（待完成）、粒子系统（待完成）
